#step1 在django项目中，同名的app中新建celery.py

from __future__ import absolute_import 
import os 
from celery import Celery 
from django.conf import settings 

# set the default Django settings module for the 'celery' program. 
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'test_django_celery.settings') 
app = Celery('test_django_celery') 

# Using a string here means the worker will not have to 
# pickle the object when using Windows. 
app.config_from_object('django.conf:settings') 

app.autodiscover_tasks(lambda: settings.INSTALLED_APPS) 

@app.task(bind=True) 
def debug_task(self): 
	print('Request: {0!r}'.format(self.request))
		

#step2 将celery.py 做成一个app; 其实就是使得django启动的时候，就加载celery应用。

"""
	简单说：将django和celery集成
	在settings.py旁边新建__init__.py，并将一下代码复制
	
"""
from __future__ import absolute_import 

# This will make sure the app is always imported when 
# Django starts so that shared_task will use this app. 
from .celery import app as celery_app
	

	
# step3 安装redis作为celery的中间件(worker)， 以及设置redis存储结果， 

"""
	celery是使用中间件在django项目和celery监控着之间传递消息， 我们使用redis来传递
	添加以下到settings.py中
	
	当然，安装redis 
	pip install redis==2.10.3
"""

# CELERY STUFF 
BROKER_URL = 'redis://localhost:6379' 
CELERY_RESULT_BACKEND = 'redis://localhost:6379'     
CELERY_ACCEPT_CONTENT = ['application/json'] 
CELERY_TASK_SERIALIZER = 'json' 
CELERY_RESULT_SERIALIZER = 'json' 
CELERY_TIMEZONE = 'Asia/Shanghai'



# step4 测试worker是否已经准备好接收任务; liunx命令运行, 而且要进入到project的目录内， 先不要关掉，（应该后面做成django启动，这个就也自动启动，包含call add函数
	# $ celery -A test_django_celery  worker  -l info

	#查询文档，了解到该命令中-A参数表示的是Celery APP的名称，这个实例中指的就是tasks.py,后面的tasks就是APP的名称，
	#worker是一个执行任务角色，后面的loglevel=info记录日志类型默认是info,这个命令启动了一个worker,用来执行程序中add这个加法任务（task）。
	
"""

		[tasks]
		  . test_django_celery.celery.debug_task

		[2017-12-22 10:25:20,943: INFO/MainProcess] Connected to redis://localhost:6379//
		[2017-12-22 10:25:20,951: INFO/MainProcess] mingle: searching for neighbors
		[2017-12-22 10:25:21,971: INFO/MainProcess] mingle: all alone
		/opt/envlzp/local/lib/python2.7/site-packages/celery/fixups/django.py:202: UserWarning: Using settings.DEBUG leads to a memory leak, never use this setting in production environments!
		  warnings.warn('Using settings.DEBUG leads to a memory leak, never '

		[2017-12-22 10:25:21,980: WARNING/MainProcess] /opt/envlzp/local/lib/python2.7/site-packages/celery/fixups/django.py:202: UserWarning: Using settings.DEBUG leads to a memory leak, never use this setting in production environments!
		  warnings.warn('Using settings.DEBUG leads to a memory leak, never '

		[2017-12-22 10:25:21,987: INFO/MainProcess] celery@vagrant-ubuntu-trusty-64 ready.


"""
# step6 构建普通Python函数任务

from __future__ import absolute_import, unicode_literals
from celery import shared_task


@shared_task(name="sum_two_numbers") 
def add(x, y): 
	return x + y

	

# step7 新建一个py或者python manage.py shell里面执行

from app01.tasks import add
c = add.delay(1,2)
c.get()


"""
此时会报错：
[2017-12-22 10:46:43,903: INFO/MainProcess] celery@vagrant-ubuntu-trusty-64 ready.
[2017-12-22 10:46:44,016: ERROR/MainProcess] Received unregistered task of type u'app01.tasks.add'.
The message has been ignored and discarded.

原因：应该是找不到tasks， 

	我没有验证的一个解决方法：在celery.py里面直接导入tasks应该可以， 或者直接在recely.py里定义tasks


经过验证的一个解决方法：

In your django settings you need to add each module that has a celery task to CELERY_IMPORTS

# 简单来说，就是在django.settigns.py里面添加一个配置项

CELERY_IMPORTS = (里面填写你有写celery task的模块)

CELERY_IMPORTS = (
    # 'reports.tasks',
    # 'some_app.some_module',
	'app01.tasks',
)

"""

# step8 修改后，重新进入python manage.py shell, 重新输入，此时不会报错

from app01.tasks import add
c = add.delay(1,2)
c.get()

	
# step9 构建周期性任务
"""refer to http://celery.readthedocs.io/en/latest/userguide/periodic-tasks.html
"""

from celery.schedules import crontab
CELERYBEAT_SCHEDULE = {   
				# Executes every Monday morning at 7:30 A.M   
				'add-every-monday-morning': {       
						'task': 'tasks.add',        
						'schedule': crontab(hour=7, minute=30, day_of_week=1),        
						'args': (16, 16),    
				},
}

# step10 在crontab里面可以设置的参数

"""class celery.schedules.crontab(minute=u'*', hour=u'*', day_of_week=u'*', day_of_month=u'*', month_of_year=u'*', **kwargs)"""


# step11 如何设置crontab的时间参数

	minute='*/15' (for every quarter) or minute='1,13,30-45,50-59/2'.
	
	hour='*/3' (for every three hours) or hour='0,8-17/2' (at midnight, and every two hours during office hours).
	
	day_of_week='mon-fri' (for weekdays only). (Beware that day_of_week='*/2' does not literally mean ‘every two days’, but ‘every day that is divisible by two’!)
	
	day_of_month='2-30/3' (for every even numbered day) or day_of_month='1-7,15-21' (for the first and third weeks of the month).
	
	such as month_of_year='*/3' (for the first month of every quarter) or month_of_year='2-12/2' (for every even numbered month).

# step12 备注1  celery.py里面的各种配置说明
"""
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'test_celery.settings')
设置这个环境变量是为了让 celery 命令能找到 Django 项目。这条语句必须出现在 Celery 实例创建之前。

app = Celery('django_celery')
这个 app 就是 Celery 

app.config_from_object('django.conf:settings')
可以将 settings 对象作为参数传入，但是更好的方式是使用字符串，因为当使用 Windows 系统或者 execv 时 celery worker 不需要序列化 settings 对象。

app.autodiscover_tasks(lambda: settings.INSTALLED_APPS)
为了重用 Django APP，通常是在单独的 tasks.py 模块中定义所有任务。
Celery 会自动发现这些模块，加上这一句后，Celery 会自动发现 Django APP 中定义的任务，
"""

# step13备注2 celery是如何找到tasks的

"""
要使celery找到相应的tasks有四种方法
1 在项目的celery中写tasks。即在djproj/djproj/celery.py中直接定义task

2 使用autodiscover 但是tasks必须定义在app目录下的名字为tasks.py的文件中，如：apps/app1/tasks.py 否则找不到 ，会报KeyError错误。

3 如果不使用autodiscover，可以在项目的celery中 import 相应的module，相当于在项目的celery中写了相应的task，如在celery.py中 import apps.app2.mytasks 

4 在settings.py中设置CELERY_IMPORTS = ('apps.app2.mytasks',) 写到module级 

"""


